{
  "actions": {
    "AnalyzeFace": {
      "document": "This API is used to perform facial feature localization (aka facial keypoint localization) on a given image and calculate 90 facial keypoints that make up the contour of the face, including eyebrows (8 points on the left and 8 on the right), eyes (8 points on the left and 8 on the right), nose (13 points), mouth (22 points), face contour (21 points), and eyeballs or pupils (2 points).\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.",
      "input": "AnalyzeFaceRequest",
      "name": "Performs facial feature localization",
      "output": "AnalyzeFaceResponse",
      "status": "online"
    },
    "CompareFace": {
      "document": "This API is used to calculate the similarity of faces in two images and return the face similarity score.\n\nIf you need to judge \"whether the person in the image is someone specified\" in scenarios such as face login, i.e., checking whether the person in a given image is someone with a known identity, we recommend using the [VerifyFace](https://intl.cloud.tencent.com/document/product/867/44983?from_cn_redirect=1) or [VerifyPerson](https://intl.cloud.tencent.com/document/product/867/44982?from_cn_redirect=1) API.\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.",
      "input": "CompareFaceRequest",
      "name": "Compares faces",
      "output": "CompareFaceResponse",
      "status": "online"
    },
    "CopyPerson": {
      "document": "This API is used to copy a person in a group to another group (without copying the description). One person can exist in up to 100 groups at the same time.\n>     \n- Note: in the case that the version of the algorithm model was 2.0 when the person was created, the copy operation will fail if the target group is not of algorithm model 2.0.",
      "input": "CopyPersonRequest",
      "name": "Copies person",
      "output": "CopyPersonResponse",
      "status": "online"
    },
    "CreateFace": {
      "document": "This API is used to add a set of face images to a person. One person can have up to 5 images. If a person exists in multiple groups, the images will be added to all those groups for the person.\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.",
      "input": "CreateFaceRequest",
      "name": "Adds face",
      "output": "CreateFaceResponse",
      "status": "online"
    },
    "CreateGroup": {
      "document": "This API is used to create an empty group. If the group already exists, an error will be returned.\nCustom description fields can be created as needed to describe persons in the group.\n\nA maximum of 100,000 groups or 50 million faces can be created under one `APPID`.\n\nThe maximum number of faces that can be included in one group varies by algorithm model version (`FaceModelVersion`), which is 1 million for v2.0 or 3 million for v3.0.",
      "input": "CreateGroupRequest",
      "name": "Creates group",
      "output": "CreateGroupResponse",
      "status": "online"
    },
    "CreatePerson": {
      "document": "This API is used to create a person and add face, name, gender, and other related information.\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.",
      "input": "CreatePersonRequest",
      "name": "Creates person",
      "output": "CreatePersonResponse",
      "status": "online"
    },
    "DeleteFace": {
      "document": "This API is used to delete the face images of a person. If the person has only one face image, an error will be returned.",
      "input": "DeleteFaceRequest",
      "name": "Deletes face",
      "output": "DeleteFaceResponse",
      "status": "online"
    },
    "DeleteGroup": {
      "document": "This API is used to delete a group and all persons in it. Meanwhile, all face information corresponding to the persons will be deleted. If a person exists in multiple groups at the same time, deleting a group will not delete the person, but the custom description field information in the group will be deleted. Custom description field information in other groups will not be affected.\n",
      "input": "DeleteGroupRequest",
      "name": "Deletes group",
      "output": "DeleteGroupResponse",
      "status": "online"
    },
    "DeletePerson": {
      "document": "This API is used to delete a person from all groups. Meanwhile, all face information of the person will be deleted.",
      "input": "DeletePersonRequest",
      "name": "Deletes person",
      "output": "DeletePersonResponse",
      "status": "online"
    },
    "DeletePersonFromGroup": {
      "document": "This API is used to remove a person from a specified group. This operation only affects the group. If the person exists only in the group, the person will be deleted, and all face information of the person will also be deleted.",
      "input": "DeletePersonFromGroupRequest",
      "name": "Deletes person from group",
      "output": "DeletePersonFromGroupResponse",
      "status": "online"
    },
    "DetectFace": {
      "document": "This API is used to detect the position, attributes, and quality information of a face in the given image. The position information includes (x, y, w, h); the face attributes include gender, age, expression, beauty, glass, hair, mask, and pose (pitch, roll, yaw); and the face quality information includes the overall quality score, sharpness, brightness, and completeness.\n\n \nThe face quality information is mainly used to evaluate the quality of the input face image. When using the Face Recognition service, we recommend evaluating the quality of the input face image first to improve the effects of subsequent processing. Application scenarios of this feature include:\n\n1. [Creating](https://intl.cloud.tencent.com/document/product/867/45014?from_cn_redirect=1)/[Adding](https://intl.cloud.tencent.com/document/product/867/45016?from_cn_redirect=1) a person in a group: this is to ensure the quality of the face information to facilitate subsequent processing.\n\n2. [Face search](https://intl.cloud.tencent.com/document/product/867/44994?from_cn_redirect=1): this is to ensure the quality of the input image to quickly find the corresponding person.\n\n3. [Face verification](https://intl.cloud.tencent.com/document/product/867/44983?from_cn_redirect=1): this is to ensure the quality of the face information to avoid cases where the verification incorrectly fails.\n\n4. Face fusion: this is to ensure the quality of the uploaded face images to improve the fusion effect.\n\n>- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.",
      "input": "DetectFaceRequest",
      "name": "Detects and analyzes face",
      "output": "DetectFaceResponse",
      "status": "online"
    },
    "DetectFaceAttributes": {
      "document": "This API is used to detect the position, attributes, and quality information of a face in the given image. The position information includes (x, y, w, h); the face attributes include gender, age, expression, beauty, glass, hair, mask, and pose (pitch, roll, yaw); and the face quality information includes the overall quality score, sharpness, brightness, and completeness.\n\n \nThe face quality information is mainly used to evaluate the quality of the input face image. When using the Face Recognition service, we recommend evaluating the quality of the input face image first to improve the effects of subsequent processing. Application scenarios of this feature include:\n\n1. [Creating](https://intl.cloud.tencent.com/document/api/1059/36964)/[Adding](https://intl.cloud.tencent.com/document/api/1059/36966) a person in a group: This is to ensure the quality of the face information to facilitate subsequent processing.\n\n2. [Face search](https://intl.cloud.tencent.com/document/api/1059/36977): This is to ensure the quality of the input image to quickly find the corresponding person.\n\n3. [Face verification](https://intl.cloud.tencent.com/document/api/1059/36972): This is to ensure the quality of the face information to avoid cases where the verification fails unexpectedly.\n\n4. Face fusion: This is to ensure the quality of the uploaded face images to improve the fusion effect.\n\n>     \n- This API is an upgrade of [DetectFace](https://intl.cloud.tencent.com/document/api/1059/36979); specifically:\n1. This API can be used to specify the face attributes that need to be computed and returned, which avoids ineffective computation and reduces time consumption.\n2. This API supports more detailed attribute items and will continue providing new features in the future.\nUse this API for corresponding face detection and attribute analysis.\n\n>     \n- Use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the parameter `SignatureMethod` to `TC3-HMAC-SHA256`.",
      "input": "DetectFaceAttributesRequest",
      "name": "Detects face and analyzes attributes",
      "output": "DetectFaceAttributesResponse",
      "status": "online"
    },
    "DetectFaceSimilarity": {
      "document": "Compare the faces in the two pictures for similarity and return the face similarity score. If you need to determine \"whether this person is someone\", that is, to verify whether the person in a picture is someone with a known identity, such as a common face login scenario, it is recommended to use [VerifyFace] (https://www.tencentcloud.com/document/product/1059/36972) or [VerifyPerson] (https://www.tencentcloud.com/document/product/1059/36971) inferface. \nPlease use the V3 version for the signature method in the public parameters, that is, configure the SignatureMethod parameter to TC3-HMAC-SHA256",
      "input": "DetectFaceSimilarityRequest",
      "name": "Face similarity detect",
      "output": "DetectFaceSimilarityResponse",
      "status": "online"
    },
    "DetectLiveFace": {
      "document": "This API is used to detect the liveness of a face in a static image uploaded by a user. Compared with dynamic liveness detection, static liveness detection does not require moving lips, shaking head, or blinking for recognition.\n\nImage-based liveness detection is suitable for scenarios where the image is a selfie or the requirement for attack defense is not high. If you have a higher security requirement for liveness detection, please use [FaceID](https://intl.cloud.tencent.com/product/faceid?from_cn_redirect=1).\n\n>     \n- The aspect ratio of the image should be close to 3:4 (width:height); otherwise, the score returned for the image will be meaningless. This API is suitable for selfie scenarios, and the score returned in other scenarios will be meaningless.\n\n>\n- During the process, please directly face the camera and keep a suitable distance to completely display your face in the recognition frame. During the recognition, keep your device still and fully show your face. You are advised to perform the detection in an environment with appropriate light and without filters.\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the parameter `SignatureMethod` to `TC3-HMAC-SHA256`.",
      "input": "DetectLiveFaceRequest",
      "name": "Detects liveness based on image",
      "output": "DetectLiveFaceResponse",
      "status": "online"
    },
    "DetectLiveFaceAccurate": {
      "document": "This API is used to detect the liveness of faces in images uploaded by users and determine whether these images are photographed.\n\nCompared with normal Image-based Liveness Detection services, this API enhances the defense capability against attacks from HD screens, printed photos, and 3D masks, as well as improves attack blocking four to five times the competing products, while maintaining high accuracy. It also supports face verification in different use cases, and satisfies the image-based liveness detection needs on mobile or PCs, making it ideal for liveness detection applications in various industries.\n\nPay-as-you-go billing officially started for this API at 00:00, August 1, 2022. For more information, see [Billing Overview](https://intl.cloud.tencent.com/document/product/867/17640?from_cn_redirect=1).",
      "input": "DetectLiveFaceAccurateRequest",
      "name": "Detects the liveness of faces in images (high precision)",
      "output": "DetectLiveFaceAccurateResponse",
      "status": "online"
    },
    "GetGroupInfo": {
      "document": "This API is used to get the group information.",
      "input": "GetGroupInfoRequest",
      "name": "Gets group information",
      "output": "GetGroupInfoResponse",
      "status": "online"
    },
    "GetGroupList": {
      "document": "This API is used to get the list of groups.",
      "input": "GetGroupListRequest",
      "name": "Gets group list",
      "output": "GetGroupListResponse",
      "status": "online"
    },
    "GetPersonBaseInfo": {
      "document": "This API is used to get the information of a specified person, including name, gender, face, etc.",
      "input": "GetPersonBaseInfoRequest",
      "name": "Gets the basic information of person",
      "output": "GetPersonBaseInfoResponse",
      "status": "online"
    },
    "GetPersonGroupInfo": {
      "document": "This API is used to get the information of a specified person, including group, description, etc.",
      "input": "GetPersonGroupInfoRequest",
      "name": "Gets the group information of person",
      "output": "GetPersonGroupInfoResponse",
      "status": "online"
    },
    "GetPersonList": {
      "document": "This API is used to get the list of persons in a specified group.",
      "input": "GetPersonListRequest",
      "name": "Gets person list",
      "output": "GetPersonListResponse",
      "status": "online"
    },
    "GetPersonListNum": {
      "document": "This API is used to get the number of persons in a specified group.",
      "input": "GetPersonListNumRequest",
      "name": "Gets person list length",
      "output": "GetPersonListNumResponse",
      "status": "online"
    },
    "ModifyGroup": {
      "document": "This API is used to modify the name, tag, and custom description field of a group.",
      "input": "ModifyGroupRequest",
      "name": "Modifies group",
      "output": "ModifyGroupResponse",
      "status": "online"
    },
    "ModifyPersonGroupInfo": {
      "document": "This API is used to modify the description of a specified person in a group.",
      "input": "ModifyPersonGroupInfoRequest",
      "name": "Modifies person description",
      "output": "ModifyPersonGroupInfoResponse",
      "status": "online"
    },
    "SearchFaces": {
      "document": "This API is used to recognize top K persons in one or more groups who are similar to the person in a given image and rank the similarity in descending order.\n\nUp to 10 faces in an image can be recognized at a time, and up to 100 groups can be searched in at a time.\n\nThe maximum number of faces in groups that can be searched for at a time is subject to the algorithm model version (`FaceModelVersion`) of groups, which is 1 million for v2.0 or 3 million for v3.0.\n\nThis API recognizes each face image of a person as an independent one. By contrast, the [SearchPersons](https://intl.cloud.tencent.com/document/product/867/44992?from_cn_redirect=1) and [SearchPersonsReturnsByGroup](https://intl.cloud.tencent.com/document/product/867/44991?from_cn_redirect=1) APIs fuse the features of all face images of a person; for example, if a person has 4 face images, they will fuse the features of the 4 face images and generate the summarized facial features of the person to make the search more accurate.\n\n\nThis API should be used together with [Group Management APIs](https://intl.cloud.tencent.com/document/product/867/45015?from_cn_redirect=1).\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the parameter `SignatureMethod` to `TC3-HMAC-SHA256`.\n\n>     \n- You cannot search for groups using different algorithm model versions (`FaceModelVersion`) at a time.",
      "input": "SearchFacesRequest",
      "name": "Searches for face",
      "output": "SearchFacesResponse",
      "status": "online"
    },
    "SearchFacesReturnsByGroup": {
      "document": "This API is used to recognize top K persons in one or more groups who are similar to the person in a given image, display the results **by group**, and rank the similarity within each group in descending order.\n\nUp to 10 faces in the image can be recognized at a time, and cross-group search is supported.\n\nThe maximum number of faces in groups that can be searched for at a time is subject to the group's algorithm model version (`FaceModelVersion`), which is 1 million for v2.0 or 3 million for v3.0.\n\nThis API recognizes each face image of a person as an independent one. By contrast, the [SearchPersons](https://intl.cloud.tencent.com/document/product/867/44992?from_cn_redirect=1) and [SearchPersonsReturnsByGroup](https://intl.cloud.tencent.com/document/product/867/44991?from_cn_redirect=1) APIs fuse the features of all face images of a person; for example, if a person has 4 face images, they will fuse the features of the 4 face images and generate the summarized facial features of the person to make the search more accurate.\n\nThis API should be used together with [Group Management APIs](https://intl.cloud.tencent.com/document/product/867/45015?from_cn_redirect=1).\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.\n\n>     \n- You cannot search for groups using different algorithm model versions (`FaceModelVersion`) at a time.\n",
      "input": "SearchFacesReturnsByGroupRequest",
      "name": "Searches for face with results returned by group",
      "output": "SearchFacesReturnsByGroupResponse",
      "status": "online"
    },
    "SearchPersons": {
      "document": "This API is used to recognize top K persons in one or more groups who are similar to the person in a given image and rank the similarity in a descending order.\n\nUp to 10 faces in an image can be recognized at a time, and up to 100 groups can be searched in at a time.\n\nThe maximum number of faces in groups that can be searched for at a time is subject to the group's algorithm model version (`FaceModelVersion`), which is 1 million for v2.0 or 3 million for v3.0.\n\nThis API fuses the features of all face images of a person; for example, if a person has 4 face images, it will fuse the features of the 4 face images and generate the summarized facial features of the person to make the person search (i.e., judging whether the face image to be recognized is of a specified person) more accurate. By contrast, the [SearchFaces](https://intl.cloud.tencent.com/document/product/867/44994?from_cn_redirect=1) and [SearchFacesReturnsByGroup](https://intl.cloud.tencent.com/document/product/867/44993?from_cn_redirect=1) APIs recognize each face image of a person as an independent one for search.\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.\n- This feature is available only to groups whose algorithm model version (`FaceModelVersion`) is 3.0.",
      "input": "SearchPersonsRequest",
      "name": "Searches for person",
      "output": "SearchPersonsResponse",
      "status": "online"
    },
    "SearchPersonsReturnsByGroup": {
      "document": "This API is used to recognize top K persons in one or more groups who are similar to the person in a given image, display the results **by group**, and rank the similarity within each group in a descending order.\n\nUp to 10 faces in the image can be recognized at a time, and cross-group search is supported.\n\nThe maximum number of faces in groups that can be searched for at a time is subject to the group's algorithm model version (`FaceModelVersion`), which is 1 million for v2.0 or 3 million for v3.0.\n\nThis API fuses the features of all face images of a person; for example, if a person has 4 face images, it will fuse the features of the 4 face images and generate the summarized facial features of the person to make the person search (i.e., judging whether the face image to be recognized is of a specified person) more accurate. By contrast, the [SearchFaces](https://intl.cloud.tencent.com/document/product/867/44994?from_cn_redirect=1) and [SearchFacesReturnsByGroup](https://intl.cloud.tencent.com/document/product/867/44993?from_cn_redirect=1) APIs recognize each face image of a person as an independent one for search.\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.\n- This feature is available only to groups whose algorithm model version (`FaceModelVersion`) is 3.0.",
      "input": "SearchPersonsReturnsByGroupRequest",
      "name": "Searches for person with results returned by group",
      "output": "SearchPersonsReturnsByGroupResponse",
      "status": "online"
    },
    "VerifyFace": {
      "document": "This API is used to judge whether a person in an image corresponds to a given `PersonId`. For more information on `PersonId`, please see [Group Management APIs](https://intl.cloud.tencent.com/document/product/867/45015?from_cn_redirect=1). \n\nThe `VerifyFace` API judges whether a person is someone specified whose information is stored in a group, and there may be multiple face images of \"someone\". By contrast, the [CompareFace](https://intl.cloud.tencent.com/document/product/867/44987?from_cn_redirect=1) API judges the similarity between two faces.\n\nThis API recognizes each face image of a person as an independent one. By contrast, the [VerifyPerson](https://intl.cloud.tencent.com/document/product/867/44982?from_cn_redirect=1) API fuses the features of all face images of a person; for example, if a person has 4 face images, the VerifyPerson API will fuse the features of the 4 face images and generate the summarized facial features of the person to make the person verification (i.e., judging whether the face image to be recognized is of a specified person) more accurate.\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the parameter `SignatureMethod` to `TC3-HMAC-SHA256`.",
      "input": "VerifyFaceRequest",
      "name": "Verifies face",
      "output": "VerifyFaceResponse",
      "status": "online"
    },
    "VerifyPerson": {
      "document": "This API is used to judge whether a person in an image corresponds to a given `PersonId`. For more information on `PersonId`, please see [Group Management APIs](https://intl.cloud.tencent.com/document/product/867/45015?from_cn_redirect=1).\nThis API fuses the features of all face images of a person; for example, if a person has 4 face images, it will fuse the features of the 4 face images and generate the summarized facial features of the person to make the person verification (i.e., judging whether the face image to be recognized is of a specified person) more accurate.\n\n The face verification APIs judge whether a person is someone specified whose information is stored in a group, and the \"someone\" may have multiple face images. By contrast, the face comparison APIs judge the similarity between two faces.\n\n\n>     \n- Please use the signature algorithm v3 to calculate the signature in the common parameters, that is, set the `SignatureMethod` parameter to `TC3-HMAC-SHA256`.\n- This feature is available only to groups whose algorithm model version (`FaceModelVersion`) is 3.0.",
      "input": "VerifyPersonRequest",
      "name": "Verifies person",
      "output": "VerifyPersonResponse",
      "status": "online"
    }
  },
  "metadata": {
    "apiVersion": "2020-03-03",
    "serviceNameCN": "人脸识别",
    "serviceShortName": "iai"
  },
  "objects": {
    "AnalyzeFaceRequest": {
      "document": "AnalyzeFace request structure.",
      "members": [
        {
          "document": "Detection mode. 0: detect all faces that appear; 1: detect the largest face. Default value: 0. The facial feature localization information (facial keypoints) of up to 10 faces can be returned.",
          "example": "0",
          "member": "uint64",
          "name": "Mode",
          "required": false,
          "type": "int"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "无",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.  \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "http://test.image.myqcloud.com/testA.jpg",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Algorithm model version used by the Face Recognition service.\n\nCurrently, `2.0` and `3.0` are supported.\n\nThis parameter is `3.0` by default starting from April 2, 2020. If it is left empty for accounts that used this API, `2.0` will be used by default.\n\nThe parameter can be set only to `3.0` for accounts that purchase the service after November 26, 2020.\n\nDifferent algorithm model versions correspond to different face recognition algorithms. The 3.0 version has a better overall effect than the legacy version and is recommended.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "required": false,
          "type": "string"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "example": "0",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "AnalyzeFaceResponse": {
      "document": "AnalyzeFace response structure.",
      "members": [
        {
          "document": "Width of requested image.",
          "member": "uint64",
          "name": "ImageWidth",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Height of requested image.",
          "member": "uint64",
          "name": "ImageHeight",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Specific information of facial feature localization (facial keypoints).",
          "member": "FaceShape",
          "name": "FaceShapeSet",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "AttributeItem": {
      "document": "Face attribute information",
      "members": [
        {
          "document": "Attribute value",
          "member": "int64",
          "name": "Type",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Probability of recognizing `Type`, which indicates the probability of correct recognition. Value range: [0,1].",
          "member": "float",
          "name": "Probability",
          "required": true,
          "type": "float",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "Candidate": {
      "document": "Most matching candidate recognized",
      "members": [
        {
          "document": "Person ID",
          "example": "person1",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Face ID, which is valid only when returned by the `SearchFaces` or `SearchFacesReturnsByGroup` API. User search APIs use facial feature fusion to search for users, for which this field is meaningless.",
          "example": "3820314501007076807",
          "member": "string",
          "name": "FaceId",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Match score of candidate. \n\nIn a face base library containing 10,000 faces, the 1%, 0.1%, and 0.01% FARs correspond to scores of 70, 80, and 90, respectively;\nIn a face base library containing 100,000 faces, the 1%, 0.1%, and 0.01% FARs correspond to scores of 80, 90, and 100, respectively;\nIn a face base library containing 300,000 faces, the 1% and 0.1% FARs correspond to scores of 85 and 95, respectively.\n\nGenerally, the score of 80 is suitable for most scenarios. We recommend choosing an appropriate score based on the actual situation, preferably no more than 90.",
          "example": "50",
          "member": "float",
          "name": "Score",
          "required": true,
          "type": "float",
          "value_allowed_null": false
        },
        {
          "document": "Person name\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "hello",
          "member": "string",
          "name": "PersonName",
          "required": true,
          "type": "string",
          "value_allowed_null": true
        },
        {
          "document": "Person gender\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "0",
          "member": "int64",
          "name": "Gender",
          "required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "document": "List of groups containing this person and their description fields\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "无",
          "member": "PersonGroupInfo",
          "name": "PersonGroupInfos",
          "required": true,
          "type": "list",
          "value_allowed_null": true
        }
      ],
      "usage": "out"
    },
    "CompareFaceRequest": {
      "document": "CompareFace request structure.",
      "members": [
        {
          "document": "Base64-encoded data of image A, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "无",
          "member": "string",
          "name": "ImageA",
          "required": false,
          "type": "string"
        },
        {
          "document": "Base64-encoded data of image B, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "无",
          "member": "string",
          "name": "ImageB",
          "required": false,
          "type": "string"
        },
        {
          "document": "URL of image A. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` of image A must be provided; if both are provided, only `Url` will be used. \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "http://test.image.myqcloud.com/testA.jpg",
          "member": "string",
          "name": "UrlA",
          "required": false,
          "type": "string"
        },
        {
          "document": "URL of image B. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` of image B must be provided; if both are provided, only `Url` will be used. \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "http://test.image.myqcloud.com/testB.jpg",
          "member": "string",
          "name": "UrlB",
          "required": false,
          "type": "string"
        },
        {
          "document": "Algorithm model version used by the Face Recognition service.\n\nCurrently, `2.0` and `3.0` are supported.\n\nThis parameter is `3.0` by default starting from April 2, 2020. If it is left empty for accounts that used this API, `2.0` will be used by default.\n\nThe parameter can be set only to `3.0` for accounts that purchase the service after November 26, 2020.\n\nDifferent algorithm model versions correspond to different face recognition algorithms. The 3.0 version has a better overall effect than the legacy version and is recommended.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "example": "0",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "example": "0",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "CompareFaceResponse": {
      "document": "CompareFace response structure.",
      "members": [
        {
          "document": "Face similarity score between two images.\nThe returned similarity score varies by algorithm version. \nIf you need to verify whether the faces in the two images are the same person, then the 0.1%, 0.01%, and 0.001% FARs on v3.0 correspond to scores of 40, 50, and 60, respectively. Generally, if the score is above 50, it can be judged that they are the same person. \nThe 0.1%, 0.01%, and 0.001% FARs on v2.0 correspond to scores of 70, 80, and 90, respectively. Generally, if the score is above 80, it can be judged that they are the same person. \nIf you need to verify whether the faces in the two images are the same person, we recommend using the `VerifyFace` API.",
          "member": "float",
          "name": "Score",
          "type": "float",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "CopyPersonRequest": {
      "document": "CopyPerson request structure.",
      "members": [
        {
          "document": "Person ID, which is the `PersonId` in the `CreatePerson` API.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "List of groups to join. The array element value is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupIds",
          "required": true,
          "type": "list"
        }
      ],
      "type": "object"
    },
    "CopyPersonResponse": {
      "document": "CopyPerson response structure.",
      "members": [
        {
          "document": "Number of groups successfully added to.",
          "member": "uint64",
          "name": "SucGroupNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "List of groups successfully added to.",
          "member": "string",
          "name": "SucGroupIds",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "CreateFaceRequest": {
      "document": "CreateFace request structure.",
      "members": [
        {
          "document": "Person ID, which is the `PersonId` in the `CreatePerson` API.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nA person can have up to 5 face images.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Images",
          "required": false,
          "type": "list"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.  \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.\nA person can have up to 5 face images.\nIf there are multiple faces in the image, only the face with the largest size will be selected.",
          "member": "string",
          "name": "Urls",
          "required": false,
          "type": "list"
        },
        {
          "document": "Only faces whose similarity to an existing face of the person is above the value of `FaceMatchThreshold` can be added successfully. \nDefault value: 60. Value range: [0,100].",
          "member": "float",
          "name": "FaceMatchThreshold",
          "required": false,
          "type": "float"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "CreateFaceResponse": {
      "document": "CreateFace response structure.",
      "members": [
        {
          "document": "Number of successfully added faces",
          "member": "uint64",
          "name": "SucFaceNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "List of IDs of successfully added faces",
          "member": "string",
          "name": "SucFaceIds",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Adding result for each face image. -1101: no face detected; -1102: image decoding failed; \n-1601: the image quality control requirement is not met; -1604: the face similarity is not above `FaceMatchThreshold`. \nOther non-zero values: algorithm service exception. \nThe order of `RetCode` values is the same as the order of `Images` or `Urls` in the input parameter.",
          "member": "int64",
          "name": "RetCode",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Indexes of successfully added faces. The order of indexes is the same as the order of `Images` or `Urls` in the input parameter. \nFor example, if there are 3 URLs in `Urls`, and the second URL fails, then the value of `SucIndexes` will be [0,2].",
          "member": "uint64",
          "name": "SucIndexes",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Frame positions of successfully added faces. The order is the same as the order of `Images` or `Urls` in the input parameter.",
          "member": "FaceRect",
          "name": "SucFaceRects",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "CreateGroupRequest": {
      "document": "CreateGroup request structure.",
      "members": [
        {
          "document": "Group name, which is modifiable, must be unique, and can contain 1 to 60 characters.",
          "example": "腾讯深圳员工库",
          "member": "string",
          "name": "GroupName",
          "required": true,
          "type": "string"
        },
        {
          "document": "Group ID, which is unmodifiable, must be unique, and can contain letters, digits, and special symbols (-%@#&_) of up to 64 B.",
          "example": "TencentShenZhenEmployee",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Custom group description field that describes the person attributes in the group, which will be applied to all persons in the group. \nUp to 5 ones can be created. \nEach custom description field can contain 1 to 30 characters. \nThe custom description field must be unique in the group. \nExample: if you set the \"custom description field\" of a group to [\"student ID\",\"employee ID\",\"mobile number\"], \nthen all the persons in the group will have description fields named \"student ID\", \"employee ID\", and \"mobile number\". \nYou can enter content in the corresponding field to register a person's student ID, employee ID, and mobile number.",
          "example": "[\"\\u4e8b\\u4e1a\\u7fa4\\n\",\"\\u90e8\\u95e8\\u540d\\n\",\"\\u7ec4\\u540d\\n\"]",
          "member": "string",
          "name": "GroupExDescriptions",
          "required": false,
          "type": "list"
        },
        {
          "document": "Group remarks, which can contain 0 to 40 characters.",
          "example": "不含实习生",
          "member": "string",
          "name": "Tag",
          "required": false,
          "type": "string"
        },
        {
          "document": "Algorithm model version used by the Face Recognition service.\n\nCurrently, `2.0` and `3.0` are supported.\n\nThis parameter is `3.0` by default starting from April 2, 2020. If it is left empty for accounts that used this API, `2.0` will be used by default.\n\nThe parameter can be set only to `3.0` for accounts that purchase the service after November 26, 2020.\n\nDifferent algorithm model versions correspond to different face recognition algorithms. The 3.0 version has a better overall effect than the legacy version and is recommended.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "required": false,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "CreateGroupResponse": {
      "document": "CreateGroup response structure.",
      "members": [
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "CreatePersonRequest": {
      "document": "CreatePerson request structure.",
      "members": [
        {
          "document": "ID of the group to join, which is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Person name, which can contain 1 to 60 characters and is modifiable and repeatable.",
          "member": "string",
          "name": "PersonName",
          "required": true,
          "type": "string"
        },
        {
          "document": "Person ID, which is unmodifiable, must be unique under a Tencent Cloud account, and can contain letters, digits, and special symbols (-%@#&_) of up to 64 B.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "0: empty; 1: male; 2: female.",
          "member": "int64",
          "name": "Gender",
          "required": false,
          "type": "int"
        },
        {
          "document": "Content of person description field, which is a `key-value` pair, can contain 0 to 60 characters, and is modifiable and repeatable.",
          "member": "PersonExDescriptionInfo",
          "name": "PersonExDescriptionInfos",
          "required": false,
          "type": "list"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.  \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "This parameter is used to control the judgment whether the face contained in the image in `Image` or `Url` corresponds to an existing person in the group. \nIf it is judged that a duplicate person exists in the group, no new person will be created, and information of the suspected duplicate person will be returned. \nOtherwise, the new person will be created. \n0: do not judge, i.e., the person will be created no matter whether a duplicate person exists in the group. \n1: low duplicate person judgment requirement (1% FAR); \n2: average duplicate person judgment requirement (0.1% FAR); \n3: high duplicate person judgment requirement (0.01% FAR); \n4: very high duplicate person judgment requirement (0.001% FAR). \nDefault value: 0.  \nNote: the higher the requirement, the lower the probability of duplicate person. The FARs corresponding to different requirements are for reference only and can be adjusted as needed.",
          "member": "uint64",
          "name": "UniquePersonControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "CreatePersonResponse": {
      "document": "CreatePerson response structure.",
      "members": [
        {
          "document": "Unique ID of face image.",
          "member": "string",
          "name": "FaceId",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Position of detected face frame.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "FaceRect",
          "name": "FaceRect",
          "type": "object",
          "value_allowed_null": true
        },
        {
          "document": "`PersonId` of suspected duplicate person. \nThis parameter is meaningful only if the `UniquePersonControl` parameter is not 0 and there is a suspected duplicate person in the group.",
          "member": "string",
          "name": "SimilarPersonId",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DeleteFaceRequest": {
      "document": "DeleteFace request structure.",
      "members": [
        {
          "document": "Person ID, which is the `PersonId` in the `CreatePerson` API.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "List of IDs of the faces to be deleted. The array element value is the `FaceId` returned by the `CreateFace` API.",
          "member": "string",
          "name": "FaceIds",
          "required": true,
          "type": "list"
        }
      ],
      "type": "object"
    },
    "DeleteFaceResponse": {
      "document": "DeleteFace response structure.",
      "members": [
        {
          "document": "Number of successfully deleted faces",
          "member": "uint64",
          "name": "SucDeletedNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "List of IDs of successfully deleted faces",
          "member": "string",
          "name": "SucFaceIds",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DeleteGroupRequest": {
      "document": "DeleteGroup request structure.",
      "members": [
        {
          "document": "Group ID, which is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DeleteGroupResponse": {
      "document": "DeleteGroup response structure.",
      "members": [
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DeletePersonFromGroupRequest": {
      "document": "DeletePersonFromGroup request structure.",
      "members": [
        {
          "document": "Person ID, which is the `PersonId` in the `CreatePerson` API.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Group ID, which is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DeletePersonFromGroupResponse": {
      "document": "DeletePersonFromGroup response structure.",
      "members": [
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DeletePersonRequest": {
      "document": "DeletePerson request structure.",
      "members": [
        {
          "document": "Person ID, which is the `PersonId` in the `CreatePerson` API.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DeletePersonResponse": {
      "document": "DeletePerson response structure.",
      "members": [
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DetectFaceAttributesRequest": {
      "document": "DetectFaceAttributes request structure.",
      "members": [
        {
          "document": "Maximum number of processable faces. \nDefault value: 1 (i.e., detecting only the face with the largest size in the image). Maximum value: 120. \nThis parameter is used to control the number of faces in the image to be detected. The smaller the value, the faster the processing.",
          "example": "1",
          "member": "uint64",
          "name": "MaxFaceNum",
          "required": false,
          "type": "int"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats. \nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "无",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. \nThe image cannot exceed 5 MB in size after being Base64-encoded. \nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used. \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low. \nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "http://test.image.myqcloud.com/testA.jpg",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Whether to return attributes such as age, gender, and emotion. \nValid values (case-insensitive): None, Age, Beauty, Emotion, Eye, Eyebrow, Gender, Hair, Hat, Headpose, Mask, Mouth, Moustache, Nose, Shape, Skin, Smile. \n  \n`None` indicates that no attributes need to be returned, which is the default value; that is, if the `FaceAttributesType` attribute is empty, the values of all attributes will be `0`.\nYou need to combine the attributes into a string and separate them by comma. The sequence of the attributes is not limited. \nFor more information on the attributes, see the output parameters as described below. \nThe face attribute information of up to 5 largest faces in the image will be returned, and `AttributesInfo` of the 6th and rest faces is meaningless.",
          "example": "eye",
          "member": "string",
          "name": "FaceAttributesType",
          "required": false,
          "type": "string"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image is not rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "example": "0",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        },
        {
          "document": "Algorithm model version used by the Face Recognition service. You can enter only `3.0` for this API.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "required": false,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DetectFaceAttributesResponse": {
      "document": "DetectFaceAttributes response structure.",
      "members": [
        {
          "document": "Width of requested image.",
          "member": "uint64",
          "name": "ImageWidth",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Height of requested image.",
          "member": "uint64",
          "name": "ImageHeight",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Face information list.",
          "member": "FaceDetailInfo",
          "name": "FaceDetailInfos",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DetectFaceRequest": {
      "document": "DetectFace request structure.",
      "members": [
        {
          "disabled": false,
          "document": "Maximum number of processable faces. Default value: 1 (i.e., detecting only the face with the largest size in the image). Maximum value: 120. \nThis parameter is used to control the number of faces in the image to be detected. The smaller the value, the faster the processing.",
          "example": "1",
          "member": "uint64",
          "name": "MaxFaceNum",
          "required": false,
          "type": "int"
        },
        {
          "disabled": false,
          "document": "Minimum height and width of face in px.\nDefault value: 34. We recommend keeping it at or above 34.\nFaces below the `MinFaceSize` value will not be detected.",
          "example": "34",
          "member": "uint64",
          "name": "MinFaceSize",
          "required": false,
          "type": "int"
        },
        {
          "disabled": false,
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "/9j/4AAQSkZJRg.....s97n//2Q==",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.  \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "https://test.image.myqcloud.com/testB.jpg",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "Whether the face attribute information (FaceAttributesInfo) needs to be returned. 0: no; 1: yes. Default value: 0. \nIf the value is not 1, it will be deemed as no need to return, and `FaceAttributesInfo` is meaningless in this case.  \nThe face attribute information of up to 5 largest faces in the image will be returned, and `FaceAttributesInfo` of the 6th and rest faces is meaningless.  \nExtracting face attribute information is quite time-consuming. If face attribute information is not required, we recommend disabling this feature to speed up face detection.",
          "example": "0",
          "member": "uint64",
          "name": "NeedFaceAttributes",
          "required": false,
          "type": "int"
        },
        {
          "disabled": false,
          "document": "Whether to enable quality detection. 0: no; 1: yes. Default value: 0. \nIf the value is not 1, it will be deemed not to perform quality detection.\nThe face quality score information of up to 30 largest faces in the image will be returned, and `FaceQualityInfo` of the 31st and rest faces is meaningless.  \nWe recommend enabling this feature for the face adding operation.",
          "example": "0",
          "member": "uint64",
          "name": "NeedQualityDetection",
          "required": false,
          "type": "int"
        },
        {
          "disabled": false,
          "document": "Algorithm model version used by the Face Recognition service.\n\nCurrently, `2.0` and `3.0` are supported.\n\nThis parameter is `3.0` by default starting from April 2, 2020. If it is left empty for accounts that used this API, `2.0` will be used by default.\n\nThe parameter can be set only to `3.0` for accounts that purchase the service after November 26, 2020.\n\nDifferent algorithm model versions correspond to different face recognition algorithms. The 3.0 version has a better overall effect than the legacy version and is recommended.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "example": "0",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "DetectFaceResponse": {
      "document": "DetectFace response structure.",
      "members": [
        {
          "disabled": false,
          "document": "Width of requested image.",
          "example": "640",
          "member": "int64",
          "name": "ImageWidth",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Height of requested image.",
          "example": "440",
          "member": "int64",
          "name": "ImageHeight",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Face information list, including face coordinate information, attribute information (if needed), and quality score information (if needed).",
          "example": "无",
          "member": "FaceInfo",
          "name": "FaceInfos",
          "output_required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Algorithm model version used for face recognition.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "output_required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, generated by the server, will be returned for every request (if the request fails to reach the server for other reasons, the request will not obtain a RequestId). RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DetectFaceSimilarityRequest": {
      "document": "DetectFaceSimilarity request structure.",
      "members": [
        {
          "disabled": false,
          "document": "A image base64 data.\n - The size after base64 encoding cannot exceed 5M. \n- The long side pixels of jpg format cannot exceed 4000, and the long side pixels of pictures in other formats cannot exceed 2000. The short side of images in all formats must be no less than 64 pixels. \n- If the picture contains multiple faces, only the face with the highest confidence is selected. - Supports PNG, JPG, JPEG, BMP, but does not support GIF images.",
          "example": "/9j/4AAQSkZJRg.....s97n//2Q==",
          "member": "string",
          "name": "ImageA",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "B image base64 data.\n - The size after base64 encoding cannot exceed 5M. \n- The long side pixels of jpg format cannot exceed 4000, and the long side pixels of pictures in other formats cannot exceed 2000. The short side of images in all formats must be no less than 64 pixels. \n- If the picture contains multiple faces, only the face with the highest confidence is selected. - Supports PNG, JPG, JPEG, BMP, but does not support GIF images.",
          "example": "/9j/4AAQSkZJRg.....s97n//2Q==",
          "member": "string",
          "name": "ImageB",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "A URL for the image. \n- The size of the corresponding image after base64 encoding cannot exceed 5M. \n- The long side pixels of jpg format cannot exceed 4000, and the long side pixels of pictures in other formats cannot exceed 2000. The short side of images in all formats must be no less than 64 pixels. \n- A The URL and Image of the picture must be provided. If both are provided, only the Url will be used. \n- Images stored in Tencent Cloud's Url can ensure higher download speed and stability. It is recommended that images be stored in Tencent Cloud. \n- The URL speed and stability of non-Tencent cloud storage may be affected to a certain extent. \n- If the picture contains multiple faces, only the face with the largest face area is selected. \n- Supports PNG, JPG, JPEG, BMP, but does not support GIF images.",
          "example": "http://test.image.myqcloud.com/testA.jpg",
          "member": "string",
          "name": "UrlA",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "B The URL of the image. \n- The size of the corresponding image after base64 encoding cannot exceed 5M. \n- The long side pixels of jpg format cannot exceed 4000, and the long side pixels of pictures in other formats cannot exceed 2000. The short side of images in all formats must be no less than 64 pixels. \n- B The URL and Image of the picture must be provided. If both are provided, only the Url will be used. \n- Images stored in Tencent Cloud's Url can ensure higher download speed and stability. It is recommended that images be stored in Tencent Cloud. \n- The URL speed and stability of non-Tencent cloud storage may be affected to a certain extent. \n- If the picture contains multiple faces, only the face with the largest face area is selected. \n- Supports PNG, JPG, JPEG, BMP, but does not support GIF images.",
          "example": "http://test.image.myqcloud.com/testB.jpg",
          "member": "string",
          "name": "UrlB",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "Image quality control. \n- Value range: 0: No control; 1: Lower quality requirements, the image is very blurry, and the eyes, nose, and mouth cover at least one or more of them; 2: General quality requirements, the image is bright, Dark, blurry or generally blurred, eyebrows covered, cheeks covered, chin covered, at least three of them; 3: High quality requirements, the image may be brighter, darker, generally blurry, eyebrows blocked, cheeks blocked, chin blocked, one or two of them; 4: Very high quality requirements, all dimensions are the best or the most , there is a slight problem in one dimension; default is 0. \n- If the image quality does not meet the requirements, the returned result will prompt that the image quality test does not meet the requirements.",
          "example": "0",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "DetectFaceSimilarityResponse": {
      "document": "DetectFaceSimilarity response structure.",
      "members": [
        {
          "disabled": false,
          "document": "The value range is [0.00, 100.00]. It is recommended that when the similarity is greater than or equal to 70, the person can be judged to be the same person, and the threshold can be adjusted according to the specific scenario (the false pass rate for a threshold of 70 is one in 1,000, and the false pass rate for a threshold of 80 is one in 10,000).",
          "example": "0.999",
          "member": "float",
          "name": "Score",
          "output_required": true,
          "type": "float",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, generated by the server, will be returned for every request (if the request fails to reach the server for other reasons, the request will not obtain a RequestId). RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DetectLiveFaceAccurateRequest": {
      "document": "DetectLiveFaceAccurate request structure.",
      "members": [
        {
          "disabled": false,
          "document": "Specifies the base64 code of the image.\n-base64-Encoded size cannot exceed 5M.\n-The long side pixel of a jpg image must not exceed 4000. the long side pixel of another format image cannot exceed 2000. \n-Specifies the image aspect ratio should be close to 3:4. mobile phone shooting proportion is best.\n-Specifies the human face dimension is greater than 100X100 pixels.\n-Supported image formats include PNG, JPG, JPEG, and BMP. GIF is not supported.",
          "example": "/9j/4AAQSkZJRg.....s97n//2Q==",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "Specifies the Url of the image.\n-Specifies the maximum size of the corresponding image after base64 encoding is 5M.\n-The long side pixel of a jpg image must not exceed 4000. the long side pixel of another format image must not exceed 2000.\n-Url or Image must be provided. if both are provided, only use Url. \n-Specifies the image aspect ratio should be close to 3:4. mobile phone shooting proportion is best.\n-Specifies the human face dimension is greater than 100X100 pixels.\n-Image storage Url on tencent cloud guarantees higher download speed and stability. it is recommended to store images on tencent cloud. non-tencent cloud storage urls may be impacted in speed and stability.\n-Supported image formats include PNG, JPG, JPEG, and BMP. GIF is not supported.",
          "example": "http://test.image.myqcloud.com/testA.jpg",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "disabled": false,
          "document": "Algorithm model version used for face recognition. Valid value: `3.0`.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "required": false,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DetectLiveFaceAccurateResponse": {
      "document": "DetectLiveFaceAccurate response structure.",
      "members": [
        {
          "disabled": false,
          "document": "Liveness scoring.\n-Value range: [0,100].\n-Determines whether it is a rephotograph based on the liveness score and threshold range.\n-Current threshold can be divided into [5,10,40,70,90]. among them, the recommended threshold is 40.",
          "example": "99",
          "member": "float",
          "name": "Score",
          "output_required": true,
          "type": "float",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Algorithm model version used for face recognition.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "output_required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, generated by the server, will be returned for every request (if the request fails to reach the server for other reasons, the request will not obtain a RequestId). RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DetectLiveFaceRequest": {
      "document": "DetectLiveFace request structure.",
      "members": [
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats (the aspect ratio of the image should be close to 3:4 (width:height); otherwise, the score returned for the image will be meaningless).\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "无",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used. \n(The aspect ratio of the image should be close to 3:4 (width:height); otherwise, the score returned for the image will be meaningless.) \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "http://test.image.myqcloud.com/testA.jpg",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Algorithm model version used by the Face Recognition service.\n\nCurrently, `2.0` and `3.0` are supported.\n\nThis parameter is `3.0` by default starting from April 2, 2020. If it is left empty for accounts that used this API, `2.0` will be used by default.\n\nThe parameter can be set only to `3.0` for accounts that purchase the service after November 26, 2020.\n\nDifferent algorithm model versions correspond to different face recognition algorithms. The 3.0 version has a better overall effect than the legacy version and is recommended.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "required": false,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "DetectLiveFaceResponse": {
      "document": "DetectLiveFace response structure.",
      "members": [
        {
          "document": "Liveness score. Value range: [0,100]. The score is generally between 80 and 100, but 0 is also a common value. As a recommendation, when the score is greater than 87, it can be judged that the person in the image is alive. You can adjust the threshold according to your specific scenario.\nThis field is meaningful only if `FaceModelVersion` is 2.0.",
          "member": "float",
          "name": "Score",
          "type": "float",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Whether liveness detection is passed.\nThis field is meaningful only if `FaceModelVersion` is 3.0.",
          "member": "bool",
          "name": "IsLiveness",
          "type": "bool",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "Eye": {
      "document": "Eye information",
      "members": [
        {
          "document": "Whether glasses are worn.\nThe `Type` values of the `AttributeItem` include: 0: no glasses; 1: general glasses; 2: sunglasses.",
          "member": "AttributeItem",
          "name": "Glass",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Whether the eyes are open.\nThe `Type` values of the `AttributeItem` include: 0: open; 1: closed.",
          "member": "AttributeItem",
          "name": "EyeOpen",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Whether the person has double eyelids.\nThe `Type` values of the `AttributeItem` include: 0: no; 1: yes.",
          "member": "AttributeItem",
          "name": "EyelidType",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Eye size.\nThe `Type` values of the `AttributeItem` include: 0: small eyes; 1: general eyes; 2: big eyes.",
          "member": "AttributeItem",
          "name": "EyeSize",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "Eyebrow": {
      "document": "Eyebrow information",
      "members": [
        {
          "document": "Eyebrow thickness.\nThe `Type` values of the `AttributeItem` include: 0: light; 1: thick.",
          "member": "AttributeItem",
          "name": "EyebrowDensity",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Eyebrow curve.\nThe `Type` values of the `AttributeItem` include: 0: flat; 1: curved.",
          "member": "AttributeItem",
          "name": "EyebrowCurve",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Eyebrow length.\nThe `Type` values of the `AttributeItem` include: 0: short; 1: long.",
          "member": "AttributeItem",
          "name": "EyebrowLength",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "FaceAttributesInfo": {
      "document": "Face attributes, including gender, age, expression, \nbeauty, glass, mask, hair, and pose (pitch, roll, yaw). Valid information will be returned only if `NeedFaceAttributes` is set to 1. The face attribute information of up to 5 largest faces in the image will be returned, and `FaceAttributesInfo` of the 6th and rest faces is meaningless.",
      "members": [
        {
          "disabled": false,
          "document": "Gender. The gender is female for the value range [0,49] and male for the value range [50,100]. The closer the value to 0 or 100, the higher the confidence. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "example": "40",
          "member": "int64",
          "name": "Gender",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Age. Value range: [0,100]. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "example": "39",
          "member": "int64",
          "name": "Age",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Expression. Value range: [0 (normal)–50 (smile)–100 (laugh)]. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "example": "13",
          "member": "int64",
          "name": "Expression",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Whether glasses are present. Valid values: true, false. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "example": "true",
          "member": "bool",
          "name": "Glass",
          "output_required": true,
          "type": "bool",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Vertical offset in degrees. Value range: [-30,30]. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless. \nWe recommend selecting images in the [-10,10] range for adding faces.",
          "example": "13",
          "member": "int64",
          "name": "Pitch",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Horizontal offset in degrees. Value range: [-30,30]. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless. \nWe recommend selecting images in the [-10,10] range for adding faces.",
          "example": "21",
          "member": "int64",
          "name": "Yaw",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Horizontal rotation in degrees. Value range: [-180,180]. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.  \nWe recommend selecting images in the [-20,20] range for adding faces.",
          "example": "54",
          "member": "int64",
          "name": "Roll",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Beauty. Value range: [0,100]. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "example": "50",
          "member": "int64",
          "name": "Beauty",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Whether hat is present. Valid values: true, false. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "true",
          "member": "bool",
          "name": "Hat",
          "output_required": true,
          "type": "bool",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Whether mask is present. Valid values: true, false. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "false",
          "member": "bool",
          "name": "Mask",
          "output_required": true,
          "type": "bool",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Hair information, including length, bang, and color. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "无",
          "member": "FaceHairAttributesInfo",
          "name": "Hair",
          "output_required": true,
          "type": "object",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Whether the eyes are open. Valid values: true, false. As long as there is more than one eye closed, `false` will be returned. If `NeedFaceAttributes` is not 1 or more than 5 faces are detected, this parameter will still be returned but meaningless.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "true",
          "member": "bool",
          "name": "EyeOpen",
          "output_required": true,
          "type": "bool",
          "value_allowed_null": true
        }
      ],
      "usage": "out"
    },
    "FaceDetailAttributesInfo": {
      "document": "Face attribute information. According to the types specified in `FaceAttributesType`, the following face attributes will be returned: Age, Beauty, \nEmotion, Eye, Eyebrow, Gender, \nHair, Hat, Headpose, Mask, Mouth, Moustache, \nNose, Shape, Skin, Smile, etc.  \nIf no types are specified in `FaceAttributesType`, the details returned by `FaceDetaiAttributesInfo` will be meaningless.",
      "members": [
        {
          "document": "Age. Value range: [0,65], where 65 indicates 65 years old or above. \nIf `FaceAttributesType` does not include `Age` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "int64",
          "name": "Age",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Beauty score. Value range: [0,100]. \nIf `FaceAttributesType` does not include `Beauty` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "int64",
          "name": "Beauty",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Emotion, including relaxed, happy, surprised, angry, sad, disgusted, and scared. \nThe `Type` values of the `AttributeItem` include: 0: relaxed; 1: happy; 2: surprised; 3: angry; 4: sad; 5: disgusted; 6: scared.\nIf `FaceAttributesType` does not include `Emotion` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "AttributeItem",
          "name": "Emotion",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Eye information, including whether glasses are worn, whether eyes are closed, whether the person has double eyelids, and the eye size. \nIf `FaceAttributesType` does not include `Eye` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "Eye",
          "name": "Eye",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Eyebrow information, including whether the eyebrows are thick, curved, or long. \nIf `FaceAttributesType` does not include `Eyebrow` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "Eyebrow",
          "name": "Eyebrow",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Gender information. \nThe `Type` values of the `AttributeItem` include: 0: male; 1: female.\t\nIf `FaceAttributesType` does not include `Gender` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "AttributeItem",
          "name": "Gender",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Hair information, including length, bang, and color. \nIf `FaceAttributesType` does not include `Hair` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "Hair",
          "name": "Hair",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Hat information, including whether a hat is worn, hat style, and hat color. \nIf `FaceAttributesType` does not include `Hat` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "Hat",
          "name": "Hat",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Pose information, including the face pitch, yaw, and roll. \nIf `FaceAttributesType` does not include `Headpose` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "HeadPose",
          "name": "HeadPose",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Mask information. \nThe `Type` values of the `AttributeItem` include: 0: no mask; 1: the mask is worn and does not cover the face; 2: the mask is worn and covers the chin; 3: the mask is worn and covers the mouth; 4: the mask is worn properly.\nIf `FaceAttributesType` does not include `Mask` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "AttributeItem",
          "name": "Mask",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Mouth information, including whether the mouth is open and the lip thickness. \nIf `FaceAttributesType` does not include `Mouth` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "Mouth",
          "name": "Mouth",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Beard information.\nThe `Type` values of the `AttributeItem` include: 0: no beard; 1: beard detected. \nIf `FaceAttributesType` does not include `Moustache` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "AttributeItem",
          "name": "Moustache",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Nose information. \nThe `Type` values of the `AttributeItem` include: 0: upturned nose; 1: aquiline nose; 2: general nose; 3: bulbous nose.\nIf `FaceAttributesType` does not include `Nose` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "AttributeItem",
          "name": "Nose",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Face shape information. \nThe `Type` values of the `AttributeItem` include: 0: square; 1: triangular; 2: oval; 3: heart-shaped; 4: round.\nIf `FaceAttributesType` does not include `Shape` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "AttributeItem",
          "name": "Shape",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Skin color information. \nThe `Type` values of the `AttributeItem` include: 0: yellow; 1: brown; 2: black; 3: white.\nIf `FaceAttributesType` does not include `Skin` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "AttributeItem",
          "name": "Skin",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Smile level. Value range: [0,100]. \nIf `FaceAttributesType` does not include `Smile` or more than 5 faces are detected, this parameter will still be returned but meaningless.",
          "member": "int64",
          "name": "Smile",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "FaceDetailInfo": {
      "document": "Face information list.",
      "members": [
        {
          "document": "Position of the detected face frame.",
          "member": "FaceRect",
          "name": "FaceRect",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Face attribute information. According to the types specified in `FaceAttributesType`, the following face attributes will be returned: age (Age), beauty score (Beauty), \nemotion (Emotion), eye information (Eye), eyebrow information (Eyebrow), gender (Gender), \nhair information (Hair), hat information (Hat), pose (Headpose), mask information (Mask), mouth information (Mouse), beard information (Moustache), \nnose information (Nose), face shape (Shape), skin color (Skin), and smile information (Smile), etc.  \nIf no types are specified in `FaceAttributesType`, the detailed items returned by `FaceDetaiAttributesInfo` will be meaningless.",
          "member": "FaceDetailAttributesInfo",
          "name": "FaceDetailAttributesInfo",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "FaceHairAttributesInfo": {
      "document": "Hair information in face attributes.",
      "members": [
        {
          "disabled": false,
          "document": "0: shaved head, 1: short hair, 2: medium hair, 3: long hair, 4: braid\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "1",
          "member": "int64",
          "name": "Length",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "0: with bangs, 1: no bangs\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "0",
          "member": "int64",
          "name": "Bang",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "0: black, 1: golden, 2: brown, 3: gray\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "1",
          "member": "int64",
          "name": "Color",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        }
      ],
      "usage": "out"
    },
    "FaceInfo": {
      "document": "Face information list.",
      "members": [
        {
          "disabled": false,
          "document": "Horizontal coordinate of the top-left vertex of the face frame.\nThe face frame encompasses the facial features and is extended accordingly. If it is larger than the image, the coordinates will be negative. \nIf you want to capture a complete face, you can set the negative coordinates to 0 if the `completeness` score meets the requirement.",
          "example": "35",
          "member": "int64",
          "name": "X",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Vertical coordinate of the top-left vertex of the face frame. \nThe face frame encompasses the facial features and is extended accordingly. If it is larger than the image, the coordinates will be negative. \nIf you want to capture a complete face, you can set the negative coordinates to 0 if the `completeness` score meets the requirement.",
          "example": "61",
          "member": "int64",
          "name": "Y",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Face frame width.",
          "example": "10",
          "member": "int64",
          "name": "Width",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Face frame height.",
          "example": "8",
          "member": "int64",
          "name": "Height",
          "output_required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Face attributes, including gender, age, expression, \nbeauty, glass, mask, hair, and pose (pitch, roll, yaw). Valid information will be returned only if `NeedFaceAttributes` is set to 1.",
          "example": "无",
          "member": "FaceAttributesInfo",
          "name": "FaceAttributesInfo",
          "output_required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "disabled": false,
          "document": "Face quality information, including score, sharpness, brightness, and completeness. Valid information will be returned only if `NeedFaceDetection` is set to 1.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "无",
          "member": "FaceQualityInfo",
          "name": "FaceQualityInfo",
          "output_required": true,
          "type": "object",
          "value_allowed_null": true
        }
      ],
      "usage": "out"
    },
    "FaceQualityCompleteness": {
      "document": "Completeness of facial features, which assesses the completeness of the eyebrows, eyes, nose, cheeks, mouth, and chin.",
      "members": [
        {
          "disabled": false,
          "document": "Eyebrow completeness. Value range: [0,100]. The higher the score, the higher the completeness. \nReference range: [0,80], which means incomplete.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "70",
          "member": "int64",
          "name": "Eyebrow",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Eye completeness. Value range: [0,100]. The higher the score, the higher the completeness. \nReference range: [0,80], which means incomplete.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "60",
          "member": "int64",
          "name": "Eye",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Nose completeness. Value range: [0,100]. The higher the score, the higher the completeness. \nReference range: [0,60], which means incomplete.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "30",
          "member": "int64",
          "name": "Nose",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Cheek completeness. Value range: [0,100]. The higher the score, the higher the completeness. \nReference range: [0,70], which means incomplete.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "10",
          "member": "int64",
          "name": "Cheek",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Mouth completeness. Value range: [0,100]. The higher the score, the higher the completeness. \nReference range: [0,50], which means incomplete.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "10",
          "member": "int64",
          "name": "Mouth",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Chin completeness. Value range: [0,100]. The higher the score, the higher the completeness. \nReference range: [0,70], which means incomplete.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "80",
          "member": "int64",
          "name": "Chin",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        }
      ],
      "usage": "out"
    },
    "FaceQualityInfo": {
      "document": "Face quality information, including score, sharpness, brightness, and completeness. Valid information will be returned only if `NeedFaceDetection` is set to 1.",
      "members": [
        {
          "disabled": false,
          "document": "Quality score. Value range: [0,100]. It comprehensively evaluates whether the image quality is suitable for face recognition; the higher the score, the higher the quality. \nIn normal cases, you only need to use `Score` as the overall quality standard score. Specific item scores such as `Sharpness`, `Brightness`, `Completeness` are for reference only.\nReference range: [0,40]: poor; [40,60]: fine; [60,80]: good; [80,100]: excellent. \nWe recommend selecting images with a score above 70 for adding faces.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "80",
          "member": "int64",
          "name": "Score",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Sharpness. Value range: [0,100]. It evaluates the sharpness of the image. The higher the score, the sharper the image. \nReference range: [0,40]: very blurry; [40,60]: blurry; [60,80]: fine; [80,100]: sharp. \nWe recommend selecting images with a score above 80 for adding faces.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "100",
          "member": "int64",
          "name": "Sharpness",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Brightness. Value range: [0,100]. The brighter the image, the higher the score. \nReference range: [0,30]: dark; [30,70]: normal; [70,100]: bright. \nWe recommend selecting images in the [30,70] range for adding faces.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "30",
          "member": "int64",
          "name": "Brightness",
          "output_required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "disabled": false,
          "document": "Completeness of facial features, which assesses the completeness of the eyebrows, eyes, nose, cheeks, mouth, and chin.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "example": "无",
          "member": "FaceQualityCompleteness",
          "name": "Completeness",
          "output_required": true,
          "type": "object",
          "value_allowed_null": true
        }
      ],
      "usage": "out"
    },
    "FaceRect": {
      "document": "Position of detected face frame",
      "members": [
        {
          "document": "Horizontal coordinate of the top-left vertex of face frame. \nThe face frame encompasses the facial features and is extended accordingly. If it is larger than the image, the coordinates will be negative. \nIf you want to capture a complete face, you can set the negative coordinates to 0 if the completeness score meets the requirement.",
          "member": "int64",
          "name": "X",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Vertical coordinate of the top-left vertex of face frame. \nThe face frame encompasses the facial features and is extended accordingly. If it is larger than the image, the coordinates will be negative. \nIf you want to capture a complete face, you can set the negative coordinates to 0 if the completeness score meets the requirement.",
          "member": "int64",
          "name": "Y",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Face width",
          "member": "uint64",
          "name": "Width",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Face height",
          "member": "uint64",
          "name": "Height",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "FaceShape": {
      "document": "Specific information of facial feature localization (facial keypoints).",
      "members": [
        {
          "document": "21 points that describe the face contour.",
          "member": "Point",
          "name": "FaceProfile",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "8 points that describe the left eye.",
          "member": "Point",
          "name": "LeftEye",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "8 points that describe the right eye.",
          "member": "Point",
          "name": "RightEye",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "8 points that describe the left eyebrow.",
          "member": "Point",
          "name": "LeftEyeBrow",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "8 points that describe the right eyebrow.",
          "member": "Point",
          "name": "RightEyeBrow",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "22 points that describe the mouth.",
          "member": "Point",
          "name": "Mouth",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "13 points that describe the nose.",
          "member": "Point",
          "name": "Nose",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "1 point that describes the left pupil.",
          "member": "Point",
          "name": "LeftPupil",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "1 point that describes the right pupil.",
          "member": "Point",
          "name": "RightPupil",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "GetGroupInfoRequest": {
      "document": "GetGroupInfo request structure.",
      "members": [
        {
          "document": "Group ID, which is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GetGroupInfoResponse": {
      "document": "GetGroupInfo response structure.",
      "members": [
        {
          "document": "Group name",
          "member": "string",
          "name": "GroupName",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Group ID",
          "member": "string",
          "name": "GroupId",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Custom group description field",
          "member": "string",
          "name": "GroupExDescriptions",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Group remarks",
          "member": "string",
          "name": "Tag",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Group creation time and date (`CreationTimestamp`), whose value is the number of milliseconds between the UNIX epoch time and the group creation time.",
          "member": "uint64",
          "name": "CreationTimestamp",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GetGroupListRequest": {
      "document": "GetGroupList request structure.",
      "members": [
        {
          "document": "Starting number. Default value: 0.",
          "member": "uint64",
          "name": "Offset",
          "required": false,
          "type": "int"
        },
        {
          "document": "Number of returned results. Default value: 10. Maximum value: 1000.",
          "member": "uint64",
          "name": "Limit",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "GetGroupListResponse": {
      "document": "GetGroupList response structure.",
      "members": [
        {
          "document": "Returned group information",
          "member": "GroupInfo",
          "name": "GroupInfos",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Total number of groups\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "uint64",
          "name": "GroupNum",
          "type": "int",
          "value_allowed_null": true
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GetPersonBaseInfoRequest": {
      "document": "GetPersonBaseInfo request structure.",
      "members": [
        {
          "document": "Person ID, which is the `PersonId` in the `CreatePerson` API.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GetPersonBaseInfoResponse": {
      "document": "GetPersonBaseInfo response structure.",
      "members": [
        {
          "document": "Person name",
          "member": "string",
          "name": "PersonName",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Person gender. 0: empty; 1: male; 2: female.",
          "member": "int64",
          "name": "Gender",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "List of the IDs of included faces",
          "member": "string",
          "name": "FaceIds",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GetPersonGroupInfoRequest": {
      "document": "GetPersonGroupInfo request structure.",
      "members": [
        {
          "document": "Person ID, which is the `PersonId` in the `CreatePerson` API.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Starting number. Default value: 0.",
          "member": "uint64",
          "name": "Offset",
          "required": false,
          "type": "int"
        },
        {
          "document": "Number of returned results. Default value: 10. Maximum value: 100.",
          "member": "uint64",
          "name": "Limit",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "GetPersonGroupInfoResponse": {
      "document": "GetPersonGroupInfo response structure.",
      "members": [
        {
          "document": "List of groups containing this person and their description fields",
          "member": "PersonGroupInfo",
          "name": "PersonGroupInfos",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Total number of groups\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "uint64",
          "name": "GroupNum",
          "type": "int",
          "value_allowed_null": true
        },
        {
          "document": "Algorithm model version used by the Face Recognition service.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": true
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GetPersonListNumRequest": {
      "document": "GetPersonListNum request structure.",
      "members": [
        {
          "document": "Group ID, which is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GetPersonListNumResponse": {
      "document": "GetPersonListNum response structure.",
      "members": [
        {
          "document": "Number of persons",
          "member": "uint64",
          "name": "PersonNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Number of faces",
          "member": "uint64",
          "name": "FaceNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GetPersonListRequest": {
      "document": "GetPersonList request structure.",
      "members": [
        {
          "document": "Group ID, which is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Starting number. Default value: 0.",
          "member": "uint64",
          "name": "Offset",
          "required": false,
          "type": "int"
        },
        {
          "document": "Number of returned results. Default value: 10. Maximum value: 1000.",
          "member": "uint64",
          "name": "Limit",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "GetPersonListResponse": {
      "document": "GetPersonList response structure.",
      "members": [
        {
          "document": "Returned person information",
          "member": "PersonInfo",
          "name": "PersonInfos",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Number of persons in the group\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "uint64",
          "name": "PersonNum",
          "type": "int",
          "value_allowed_null": true
        },
        {
          "document": "Number of faces in the group\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "uint64",
          "name": "FaceNum",
          "type": "int",
          "value_allowed_null": true
        },
        {
          "document": "Algorithm model version used for face recognition.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": true
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "GroupCandidate": {
      "document": "Recognition result items by group",
      "members": [
        {
          "document": "Group ID.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Most matching candidate recognized",
          "member": "Candidate",
          "name": "Candidates",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "GroupExDescriptionInfo": {
      "document": "Custom description field of the group to be modified, which is a `key-value` pair.",
      "members": [
        {
          "document": "Custom group description field index, whose value starts from 0.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "uint64",
          "name": "GroupExDescriptionIndex",
          "required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "document": "Content of the custom group description field to be updated",
          "member": "string",
          "name": "GroupExDescription",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        }
      ],
      "usage": "in"
    },
    "GroupInfo": {
      "document": "Returned group information",
      "members": [
        {
          "document": "Group name",
          "member": "string",
          "name": "GroupName",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Group ID",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Custom group description field\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "string",
          "name": "GroupExDescriptions",
          "required": true,
          "type": "list",
          "value_allowed_null": true
        },
        {
          "document": "Group remarks\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "string",
          "name": "Tag",
          "required": true,
          "type": "string",
          "value_allowed_null": true
        },
        {
          "document": "Algorithm model version used for face recognition.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "string",
          "name": "FaceModelVersion",
          "required": true,
          "type": "string",
          "value_allowed_null": true
        },
        {
          "document": "Group creation time and date (`CreationTimestamp`), whose value is the number of milliseconds between the UNIX epoch time and the group creation time. \nThe UNIX epoch time is 00:00:00, Thursday, January 1, 1970, Coordinated Universal Time (UTC). For more information, please see the UNIX time document.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "uint64",
          "name": "CreationTimestamp",
          "required": true,
          "type": "int",
          "value_allowed_null": true
        }
      ],
      "usage": "out"
    },
    "Hair": {
      "document": "Hair information",
      "members": [
        {
          "document": "Hair length information.\nThe `Type` values of the `AttributeItem` include: 0: bald, 1: short hair, 2: medium hair, 3: long hair, 4: braid.",
          "member": "AttributeItem",
          "name": "Length",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Bang information.\nThe `Type` values of the `AttributeItem` include: 0: no bang; 1: bang detected.",
          "member": "AttributeItem",
          "name": "Bang",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Hair color information.\nThe `Type` values of the `AttributeItem` include: 0: black; 1: golden; 2: brown; 3: gray.",
          "member": "AttributeItem",
          "name": "Color",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "Hat": {
      "document": "Hat information",
      "members": [
        {
          "document": "Hat wearing status information.\nThe `Type` values of the `AttributeItem` include: 0: no hat; 1: general hat; 2: helmet; 3: security guard hat.",
          "member": "AttributeItem",
          "name": "Style",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Hat color.\nThe `Type` values of the `AttributeItem` include: 0: no hat; 1: red; 2: yellow; 3: blue; 4: black; 5: gray; 6: mixed colors.",
          "member": "AttributeItem",
          "name": "Color",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "HeadPose": {
      "document": "Pose information.",
      "members": [
        {
          "document": "Pitch. Value range: [-30,30].",
          "member": "int64",
          "name": "Pitch",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Yaw. Value range: [-30,30].",
          "member": "int64",
          "name": "Yaw",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Roll. Value range: [-180,180].",
          "member": "int64",
          "name": "Roll",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "ModifyGroupRequest": {
      "document": "ModifyGroup request structure.",
      "members": [
        {
          "document": "Group ID, which is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Group name",
          "member": "string",
          "name": "GroupName",
          "required": false,
          "type": "string"
        },
        {
          "document": "Custom description field of the group to be modified, which is a `key-value` pair.",
          "member": "GroupExDescriptionInfo",
          "name": "GroupExDescriptionInfos",
          "required": false,
          "type": "list"
        },
        {
          "document": "Group remarks",
          "member": "string",
          "name": "Tag",
          "required": false,
          "type": "string"
        }
      ],
      "type": "object"
    },
    "ModifyGroupResponse": {
      "document": "ModifyGroup response structure.",
      "members": [
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "ModifyPersonGroupInfoRequest": {
      "document": "ModifyPersonGroupInfo request structure.",
      "members": [
        {
          "document": "Group ID, which is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Person ID, which is the `PersonId` in the `CreatePerson` API.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Custom description field of the person to be modified, which is a `key-value` pair.",
          "member": "PersonExDescriptionInfo",
          "name": "PersonExDescriptionInfos",
          "required": true,
          "type": "list"
        }
      ],
      "type": "object"
    },
    "ModifyPersonGroupInfoResponse": {
      "document": "ModifyPersonGroupInfo response structure.",
      "members": [
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "Mouth": {
      "document": "Mouth information",
      "members": [
        {
          "document": "Whether the mouth is open.\nThe `Type` values of the `AttributeItem` include: 0: closed; 1: open.",
          "member": "AttributeItem",
          "name": "MouthOpen",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "PersonExDescriptionInfo": {
      "document": "Custom description field of the person to be modified, which is a `key-value` pair.",
      "members": [
        {
          "document": "Person description field index, whose value starts from 0.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "uint64",
          "name": "PersonExDescriptionIndex",
          "required": true,
          "type": "int",
          "value_allowed_null": true
        },
        {
          "document": "Content of the person description field to be updated",
          "member": "string",
          "name": "PersonExDescription",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        }
      ],
      "usage": "in"
    },
    "PersonGroupInfo": {
      "document": "List of groups containing this person and their description fields",
      "members": [
        {
          "document": "ID of the group that contains this person",
          "member": "string",
          "name": "GroupId",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Content of person description field",
          "member": "string",
          "name": "PersonExDescriptions",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "PersonInfo": {
      "document": "Returned person information",
      "members": [
        {
          "document": "Person name",
          "member": "string",
          "name": "PersonName",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Person ID",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "Person gender",
          "member": "int64",
          "name": "Gender",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Content of person description field",
          "member": "string",
          "name": "PersonExDescriptions",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "List of contained face images",
          "member": "string",
          "name": "FaceIds",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Person creation time, measured in the number of milliseconds elapsed since the Unix epoch \nThe Unix epoch is 00:00:00, Thursday, January 1, 1970, Coordinated Universal Time (UTC). For more information, please see the Unix time document.",
          "member": "uint64",
          "name": "CreationTimestamp",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "Point": {
      "document": "Coordinates",
      "members": [
        {
          "document": "X coordinate",
          "member": "int64",
          "name": "X",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Y coordinate",
          "member": "int64",
          "name": "Y",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "Result": {
      "document": "Face recognition result",
      "members": [
        {
          "document": "Most matching candidate recognized",
          "member": "Candidate",
          "name": "Candidates",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Position of detected face frame",
          "member": "FaceRect",
          "name": "FaceRect",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "The status return code for the face image detected. Valid values: `0` - normal; `-1601` - the image does not meet the quality requirements, in which case `Candidate` is empty; `-1604` - the face similarity is not higher than `FaceMatchThreshold`.",
          "member": "int64",
          "name": "RetCode",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "ResultsReturnsByGroup": {
      "document": "Recognition result.\n",
      "members": [
        {
          "document": "Position of detected face frame",
          "member": "FaceRect",
          "name": "FaceRect",
          "required": true,
          "type": "object",
          "value_allowed_null": false
        },
        {
          "document": "Recognition result.",
          "member": "GroupCandidate",
          "name": "GroupCandidates",
          "required": true,
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Status return code of detected face image. 0: normal. \n-1601: the image quality control requirement is not met; in this case, `Candidate` is empty.",
          "member": "int64",
          "name": "RetCode",
          "required": true,
          "type": "int",
          "value_allowed_null": false
        }
      ],
      "usage": "out"
    },
    "SearchFacesRequest": {
      "document": "SearchFaces request structure.",
      "members": [
        {
          "document": "List of groups to be searched in (up to 100). The array element value is the `GroupId` in the `CreateGroup` API.\nYou cannot search for groups using different algorithm model versions (`FaceModelVersion`) at a time.",
          "example": "[\"TencentShenZhenEmployee\\n\"]",
          "member": "string",
          "name": "GroupIds",
          "required": true,
          "type": "list"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "无",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.  \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "http://test.image.myqcloud.com/testA.jpg",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Maximum number of recognizable faces. Default value: 1 (i.e., detecting only the face with the largest size in the image). Maximum value: 10. \n`MaxFaceNum` is used to control the number of faces to be searched for if there are multiple faces in the input image to be recognized. \nFor example, if the input image in `Image` or `Url` contains multiple faces and `MaxFaceNum` is 5, top 5 faces with the largest size in the image will be recognized.",
          "example": "1",
          "member": "uint64",
          "name": "MaxFaceNum",
          "required": false,
          "type": "int"
        },
        {
          "document": "Minimum height and width of face in px. Default value: 34. Face images whose value is below 34 cannot be recognized. We recommend setting this parameter to 80.",
          "example": "40",
          "member": "uint64",
          "name": "MinFaceSize",
          "required": false,
          "type": "int"
        },
        {
          "document": "Number of the most similar persons returned for one single recognized face image. Default value: 5. Maximum value: 100. \nFor example, if `MaxFaceNum` is 1 and `MaxPersonNum` is 8, information of the top 8 most similar persons will be returned.\nThe greater the value, the longer the processing time. We recommend setting a value below 10.",
          "example": "5",
          "member": "uint64",
          "name": "MaxPersonNum",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to return person details. 0: no; 1: yes. Default value: 0. Other values will be considered as 0 by default.",
          "example": "0",
          "member": "int64",
          "name": "NeedPersonInfo",
          "required": false,
          "type": "int"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "example": "0",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "In the output parameter `Score`, the result will be returned only if the result value is above the `FaceMatchThreshold` value. Default value: 0.",
          "example": "0",
          "member": "float",
          "name": "FaceMatchThreshold",
          "required": false,
          "type": "float"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "example": "0",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "SearchFacesResponse": {
      "document": "SearchFaces response structure.",
      "members": [
        {
          "document": "Recognition result.",
          "member": "Result",
          "name": "Results",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Number of faces included in searched groups.",
          "member": "uint64",
          "name": "FaceNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "SearchFacesReturnsByGroupRequest": {
      "document": "SearchFacesReturnsByGroup request structure.",
      "members": [
        {
          "document": "List of groups to be searched in (up to 60). The array element value is the `GroupId` in the `CreateGroup` API.\nYou cannot search for groups using different algorithm model versions (`FaceModelVersion`) at a time.",
          "example": "[\"TencentShenZhenEmployee\\n\"]",
          "member": "string",
          "name": "GroupIds",
          "required": true,
          "type": "list"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "无",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.\nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability.\nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "example": "http://test.image.myqcloud.com/testA.jpg",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Maximum number of recognizable faces. Default value: 1 (i.e., detecting only the face with the largest size in the image). Maximum value: 10.\n`MaxFaceNum` is used to control the number of faces to be searched for if there are multiple faces in the input image to be recognized.\nFor example, if the input image in `Image` or `Url` contains multiple faces and `MaxFaceNum` is 5, top 5 faces with the largest size in the image will be recognized.",
          "example": "1",
          "member": "uint64",
          "name": "MaxFaceNum",
          "required": false,
          "type": "int"
        },
        {
          "document": "Minimum height and width of face in px. Default value: 34. A value below 34 will affect the search accuracy. We recommend setting this parameter to 80.",
          "example": "40",
          "member": "uint64",
          "name": "MinFaceSize",
          "required": false,
          "type": "int"
        },
        {
          "document": "Detected faces, which is corresponding to the maximum number of returned most matching persons. Default value: 5. Maximum value: 10.  \nFor example, if `MaxFaceNum` is 3, `MaxPersonNumPerGroup` is 5, and the `GroupIds` length is 3, up to 45 (3 * 5 * 3) persons will be returned.",
          "example": "5",
          "member": "uint64",
          "name": "MaxPersonNumPerGroup",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to return person details. 0: no; 1: yes. Default value: 0. Other values will be considered as 0 by default.",
          "example": "0",
          "member": "int64",
          "name": "NeedPersonInfo",
          "required": false,
          "type": "int"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "example": "0",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "In the output parameter `Score`, the result will be returned only if the result value is greater than or equal to the `FaceMatchThreshold` value.\nDefault value: 0.\nValue range: [0.0,100.0).",
          "example": "0",
          "member": "float",
          "name": "FaceMatchThreshold",
          "required": false,
          "type": "float"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "example": "0",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "SearchFacesReturnsByGroupResponse": {
      "document": "SearchFacesReturnsByGroup response structure.",
      "members": [
        {
          "document": "Number of faces included in searched groups.",
          "member": "uint64",
          "name": "FaceNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Recognition result.",
          "member": "ResultsReturnsByGroup",
          "name": "ResultsReturnsByGroup",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "SearchPersonsRequest": {
      "document": "SearchPersons request structure.",
      "members": [
        {
          "document": "List of groups to be searched in (up to 100). The array element value is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupIds",
          "required": true,
          "type": "list"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.\nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability.\nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Maximum number of recognizable faces. Default value: 1 (i.e., detecting only the face with the largest size in the image). Maximum value: 10.\n`MaxFaceNum` is used to control the number of faces to be searched for if there are multiple faces in the input image to be recognized.\nFor example, if the input image in `Image` or `Url` contains multiple faces and `MaxFaceNum` is 5, top 5 faces with the largest size in the image will be recognized.",
          "member": "uint64",
          "name": "MaxFaceNum",
          "required": false,
          "type": "int"
        },
        {
          "document": "Minimum height and width of face in px. Default value: 34. A value below 34 will affect the search accuracy. We recommend setting this parameter to 80.",
          "member": "uint64",
          "name": "MinFaceSize",
          "required": false,
          "type": "int"
        },
        {
          "document": "Number of the most similar persons returned for one single recognized face image. Default value: 5. Maximum value: 100.\nFor example, if `MaxFaceNum` is 1 and `MaxPersonNum` is 8, information of the top 8 most similar persons will be returned.\nThe greater the value, the longer the processing time. We recommend setting a value below 10.",
          "member": "uint64",
          "name": "MaxPersonNum",
          "required": false,
          "type": "int"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "In the output parameter `Score`, the result will be returned only if the result value is greater than or equal to the `FaceMatchThreshold` value. Default value: 0. Value range: [0.0,100.0).",
          "member": "float",
          "name": "FaceMatchThreshold",
          "required": false,
          "type": "float"
        },
        {
          "document": "Whether to return person details. 0: no; 1: yes. Default value: 0. Other values will be considered as 0 by default.",
          "member": "int64",
          "name": "NeedPersonInfo",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "SearchPersonsResponse": {
      "document": "SearchPersons response structure.",
      "members": [
        {
          "document": "Recognition result.",
          "member": "Result",
          "name": "Results",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Number of the persons included in searched groups. If the quality of all faces in the input image does not meet the requirement, 0 will be returned.",
          "member": "uint64",
          "name": "PersonNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.\nNote: this field may return null, indicating that no valid values can be obtained.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": true
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "SearchPersonsReturnsByGroupRequest": {
      "document": "SearchPersonsReturnsByGroup request structure.",
      "members": [
        {
          "document": "List of groups to be searched in (up to 60). The array element value is the `GroupId` in the `CreateGroup` API.",
          "member": "string",
          "name": "GroupIds",
          "required": true,
          "type": "list"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.\nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability.\nThe download speed and stability of non-Tencent Cloud URLs may be low.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Maximum number of recognizable faces. Default value: 1 (i.e., detecting only the face with the largest size in the image). Maximum value: 10.\n`MaxFaceNum` is used to control the number of faces to be searched for if there are multiple faces in the input image to be recognized.\nFor example, if the input image in `Image` or `Url` contains multiple faces and `MaxFaceNum` is 5, top 5 faces with the largest size in the image will be recognized.",
          "member": "uint64",
          "name": "MaxFaceNum",
          "required": false,
          "type": "int"
        },
        {
          "document": "Minimum height and width of face in px. Default value: 34. A value below 34 will affect the search accuracy. We recommend setting this parameter to 80.",
          "member": "uint64",
          "name": "MinFaceSize",
          "required": false,
          "type": "int"
        },
        {
          "document": "Detected faces, which is corresponding to the maximum number of returned most matching persons. Default value: 5. Maximum value: 10.  \nFor example, if `MaxFaceNum` is 3, `MaxPersonNumPerGroup` is 5, and the `GroupIds` length is 3, up to 45 (3 * 5 * 3) persons will be returned.",
          "member": "uint64",
          "name": "MaxPersonNumPerGroup",
          "required": false,
          "type": "int"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "In the output parameter `Score`, the result will be returned only if the result value is above the `FaceMatchThreshold` value. Default value: 0.",
          "member": "float",
          "name": "FaceMatchThreshold",
          "required": false,
          "type": "float"
        },
        {
          "document": "Whether to return person details. 0: no; 1: yes. Default value: 0. Other values will be considered as 0 by default.",
          "member": "int64",
          "name": "NeedPersonInfo",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "SearchPersonsReturnsByGroupResponse": {
      "document": "SearchPersonsReturnsByGroup response structure.",
      "members": [
        {
          "document": "Number of the persons included in searched groups. If the quality of all faces in the input image does not meet the requirement, 0 will be returned.",
          "member": "uint64",
          "name": "PersonNum",
          "type": "int",
          "value_allowed_null": false
        },
        {
          "document": "Recognition result.",
          "member": "ResultsReturnsByGroup",
          "name": "ResultsReturnsByGroup",
          "type": "list",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "VerifyFaceRequest": {
      "document": "VerifyFace request structure.",
      "members": [
        {
          "document": "ID of the person to be verified. For more information on `PersonId`, please see the group management APIs.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Base64-encoded image data, which cannot exceed 5 MB.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL. The image cannot exceed 5 MB in size after being Base64-encoded.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nEither `Url` or `Image` must be provided; if both are provided, only `Url` will be used.  \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "VerifyFaceResponse": {
      "document": "VerifyFace response structure.",
      "members": [
        {
          "document": "Similarity between given face image and `PersonId`. If there are multiple faces under the `PersonId`, the score of the highest similarity will be returned.\n\nThe returned similarity score varies by algorithm version.\nIf you need to verify whether the faces in the two images are the same person, then the 0.1%, 0.01%, and 0.001% FARs on v3.0 correspond to scores of 40, 50, and 60, respectively. Generally, if the score is above 50, it can be judged that they are the same person.\nThe 0.1%, 0.01%, and 0.001% FARs on v2.0 correspond to scores of 70, 80, and 90, respectively. Generally, if the score is above 80, it can be judged that they are the same person.",
          "example": "100",
          "member": "float",
          "name": "Score",
          "required": true,
          "type": "float",
          "value_allowed_null": false
        },
        {
          "document": "Whether the person is the one in the image. The fixed threshold score is 60. If you want to adjust the threshold more flexibly, you can take the returned `Score` parameter value for judgment.",
          "example": "1",
          "member": "bool",
          "name": "IsMatch",
          "required": true,
          "type": "bool",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition in the group where the `Person` is, which is set when the group is created.",
          "example": "3.0",
          "member": "string",
          "name": "FaceModelVersion",
          "required": true,
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    },
    "VerifyPersonRequest": {
      "document": "VerifyPerson request structure.",
      "members": [
        {
          "document": "ID of the person to be verified. For more information on `PersonId`, please see the group management APIs.",
          "member": "string",
          "name": "PersonId",
          "required": true,
          "type": "string"
        },
        {
          "document": "Base64-encoded data of the image.\nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Image",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image URL \nThe long side cannot exceed 4,000 px for images in JPG format or 2,000 px for images in other formats.\n Either `Url` or `Image` must be provided; if both are provided, only `Url` will be used. \nWe recommend storing the image in Tencent Cloud, as a Tencent Cloud URL can guarantee higher download speed and stability. \nThe download speed and stability of non-Tencent Cloud URLs may be low.\nIf there are multiple faces in the image, only the face with the largest size will be selected.\nPNG, JPG, JPEG, and BMP images are supported, while GIF images are not.",
          "member": "string",
          "name": "Url",
          "required": false,
          "type": "string"
        },
        {
          "document": "Image quality control. \n0: no control. \n1: low quality requirement. The image has one or more of the following problems: extreme blurriness, covered eyes, covered nose, and covered mouth. \n2: average quality requirement. The image has at least three of the following problems: excessive brightness, excessive dimness, blurriness or average blurriness, covered eyebrows, covered cheeks, and covered chin. \n3: high-quality requirement. The image has one to two of the following problems: excessive brightness, excessive dimness, average blurriness, covered eyebrows, covered cheeks, and covered chin. \n4: very high-quality requirement. The image is optimal in all dimensions or only has a slight problem in one dimension. \nDefault value: 0. \nIf the image quality does not meet the requirement, the returned result will prompt that the detected image quality is unsatisfactory.",
          "member": "uint64",
          "name": "QualityControl",
          "required": false,
          "type": "int"
        },
        {
          "document": "Whether to enable the support for rotated image recognition. 0: no; 1: yes. Default value: 0. When the face in the image is rotated and the image has no EXIF information, if this parameter is not enabled, the face in the image cannot be correctly detected and recognized. If you are sure that the input image contains EXIF information or the face in the image will not be rotated, do not enable this parameter, as the overall time consumption may increase by hundreds of milliseconds after it is enabled.",
          "member": "uint64",
          "name": "NeedRotateDetection",
          "required": false,
          "type": "int"
        }
      ],
      "type": "object"
    },
    "VerifyPersonResponse": {
      "document": "VerifyPerson response structure.",
      "members": [
        {
          "document": "Similarity between given face image and `PersonId`. If there are multiple faces under the `PersonId`, their information will be fused for verification.",
          "member": "float",
          "name": "Score",
          "type": "float",
          "value_allowed_null": false
        },
        {
          "document": "Whether the person in the image matches the `PersonId`.",
          "member": "bool",
          "name": "IsMatch",
          "type": "bool",
          "value_allowed_null": false
        },
        {
          "document": "Algorithm model version used for face recognition in the group where the `Person` is, which is set when the group is created.",
          "member": "string",
          "name": "FaceModelVersion",
          "type": "string",
          "value_allowed_null": false
        },
        {
          "document": "The unique request ID, which is returned for each request. RequestId is required for locating a problem.",
          "member": "string",
          "name": "RequestId",
          "type": "string"
        }
      ],
      "type": "object"
    }
  },
  "version": "1.0"
}